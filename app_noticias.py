# -*- coding: utf-8 -*-
"""Buscador de NotÃ­cias sobre Contrave / Merck.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pRzf98ffqo-D8KmamRMYR4XCiOVxjBCr
"""

# -----------------------------
# ImportaÃ§Ãµes
# -----------------------------
import streamlit as st
import feedparser
import pandas as pd
from datetime import datetime, timedelta
from dateutil import parser
from io import BytesIO

# -----------------------------
# ConfiguraÃ§Ãµes padrÃ£o
# -----------------------------
TERMS_PADRAO = [
    "Contrave", "Bupropiona", "Naltrexona",
    "Bupropiona + naltrexona", "Contrave XR",
    "Emagrecimento farmacolÃ³gico",
    "Medicamento para obesidade",
    "Tratamento de obesidade",
    "Merck",
    "Eurofarma"
]

RSS_FEEDS = [
    "https://g1.globo.com/rss/g1/economia/",
    "https://g1.globo.com/rss/g1/saude/",
    "https://www.cnnbrasil.com.br/feed/",
    "https://www.uol.com.br/feed/noticias/saude/",
    "https://www1.folha.uol.com.br/rss/saude.xml",
    "https://www.gov.br/anvisa/pt-br/assuntos/noticias?format=rss",
    "https://www.fda.gov/about-fda/press-announcements.atom",
    "https://abc-farma.com.br/feed/",
    "https://www.kairosnews.com.br/feed/",
    "https://www.pharmaceutical-technology.com/feed/",
    "https://www.merck.com/news/rss.xml",
    "https://www.eurofarma.com.br/noticias/feed/",
    "https://www.pfizer.com/news/rss.xml",
    "https://www.novartis.com/news/media-releases/rss.xml",
    "https://www.roche.com/media/newsfeed.xml"
]

# -----------------------------
# Streamlit App
# -----------------------------
st.title("ðŸ” Buscador de NotÃ­cias sobre Contrave / Merck ")
st.markdown("Busque notÃ­cias recentes em diversos sites sobre medicamentos e empresas farmacÃªuticas.")

# Mostrar termos padrÃ£o
st.subheader("ðŸ“Œ Termos de busca padrÃ£o")
st.write(", ".join(TERMS_PADRAO))

# Input do usuÃ¡rio para novos termos
novos_termos = st.text_input("Adicionar termos extras separados por vÃ­rgula", "")
TERMS = TERMS_PADRAO + [t.strip() for t in novos_termos.split(",") if t.strip() != ""]

# Input do usuÃ¡rio para quantidade de dias
DIAS_BUSCA = st.number_input("Buscar notÃ­cias dos Ãºltimos X dias", min_value=1, max_value=365, value=180)

# Mostrar sites que serÃ£o consultados
st.subheader("ðŸŒ Sites que serÃ£o consultados")
for site in RSS_FEEDS:
    st.write("-", site)

# BotÃ£o para iniciar a busca
if st.button("ðŸš€ Buscar NotÃ­cias"):

    st.info("Buscando notÃ­cias... Isso pode levar alguns segundos dependendo do nÃºmero de sites.")

    # -----------------------------
    # FunÃ§Ã£o para buscar RSS e filtrar
    # -----------------------------
    def buscar_rss(feed_url, dias=DIAS_BUSCA):
        parsed = feedparser.parse(feed_url)
        results = []
        limite_data = datetime.now() - timedelta(days=dias)

        for entry in parsed.entries:
            pub_date = None
            if "published" in entry:
                try:
                    pub_date = parser.parse(entry.published)
                    if pub_date.tzinfo is not None:
                        pub_date = pub_date.replace(tzinfo=None)
                except:
                    pub_date = None

            if pub_date is None or pub_date >= limite_data:
                title = entry.get("title", "")
                summary = entry.get("summary", "")
                content = title + " " + summary
                if any(term.lower() in content.lower() for term in TERMS):
                    results.append({
                        "fonte": feed_url,
                        "title": title,
                        "link": entry.get("link"),
                        "date": str(pub_date) if pub_date else None,
                        "content": content
                    })
        return results

    # -----------------------------
    # Rodar buscas
    # -----------------------------
    all_results = []

    for feed in RSS_FEEDS:
        st.write(f"Buscando: {feed}")
        try:
            feed_results = buscar_rss(feed)
            all_results.extend(feed_results)
        except Exception as e:
            st.error(f"Erro ao processar feed {feed}: {e}")

    # -----------------------------
    # Transformar em DataFrame
    # -----------------------------
    df = pd.DataFrame(all_results).drop_duplicates(subset=["title"])

    if df.empty:
        st.warning(f"Nenhuma notÃ­cia encontrada nos Ãºltimos {DIAS_BUSCA} dias para os termos pesquisados.")
    else:
        st.success(f"{len(df)} notÃ­cias encontradas:")
        st.dataframe(df)

        # Exportar para Excel
        output = BytesIO()
        df.to_excel(output, index=False, engine='xlsxwriter')
        output.seek(0)

        st.download_button(
            label="ðŸ“¥ Baixar Excel",
            data=output,
            file_name=f"noticias_personalizadas_{datetime.now().strftime('%Y%m%d_%H%M')}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )